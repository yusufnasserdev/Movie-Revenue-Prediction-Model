{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "from tmdbv3api import Movie\n",
    "from tmdbv3api import TMDb\n",
    "\n",
    "import keys  # TMDb API key file\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Reading the train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reading csv files\n",
    "movies_base = pd.read_csv('datasets/2/train/movies-revenue-classification.csv')\n",
    "movies_director = pd.read_csv('datasets/2/train/movie-director.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Checking nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_base.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Joining directors dataset into the movies (main) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merging dataframes; how = 'left' := use only keys from left frame.\n",
    "df = pd.merge(movies_base, movies_director, on='name', how='left')\n",
    "\n",
    "# displaying result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Filling the null directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Formatting the release_date to match the TMDb date format\n",
    "\n",
    "for i, movie in df.iterrows():\n",
    "    # Parse date from a string and return a datetime.datetime\n",
    "    release_date = parse(movie['release_date'])\n",
    "    # Remove the time from it reducing it to just the date\n",
    "    release_date = release_date.date()\n",
    "\n",
    "    # Parser doesn't do well with dates prior to the 80s\n",
    "    # Correcting the dates newer than this year to a century earlier\n",
    "    if release_date.year > 2023:\n",
    "        release_date = release_date.replace(year=release_date.year - 100)\n",
    "\n",
    "    # Editing the value at the original dataframe\n",
    "    df.at[i, 'release_date'] = release_date\n",
    "\n",
    "df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Initializing TMDb API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using the TMDb to fill out the missing director from the original dataset\n",
    "\n",
    "# https://github.com/AnthonyBloomer/tmdbv3api\n",
    "# https://developers.themoviedb.org/3/getting-started/introduction\n",
    "\n",
    "# Creating a base class instance from the api library\n",
    "tmdb = TMDb()\n",
    "tmdb.api_key = keys.tmdb_key\n",
    "tmdb.language = 'en'\n",
    "tmdb.debug = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Using the TMDb API to fill missing directors via the movie title and its release date\n",
    "Since the director name is still not encoded, the director's popularity score will replace it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a Movie instance to search by the movie details\n",
    "movie = Movie()\n",
    "\n",
    "for i, mov in df.iterrows():\n",
    "    search = movie.search(mov['name'])  # Search by the movie title\n",
    "    for res in search:\n",
    "        try:\n",
    "            # Confirming the search results by the release date year\n",
    "            mov_date_str = str(mov['release_date'])\n",
    "            if res['release_date'][:4] == mov_date_str[:4]:\n",
    "                # Extracting the director from the movie credits\n",
    "                for member in movie.credits(res.id)['crew']:\n",
    "                    if member['job'] == 'Director':\n",
    "                        # Editing the value at the original dataframe\n",
    "                        df.at[i, 'director'] = member['popularity']\n",
    "                        break\n",
    "                break\n",
    "        except BaseException as error:\n",
    "            print('An exception occurred: {}'.format(error) + \" \" + mov['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Encoding the MPAA Rating and Genre to indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill the nulls with the mode\n",
    "df['director'] = df['director'].fillna(value=df['director'].median())\n",
    "df['genre'] = df['genre'].fillna(value=df['genre'].mode()[0])\n",
    "df['MPAA_rating'] = df['MPAA_rating'].fillna(value=df['MPAA_rating'].mode()[0])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocessing genre and MPAA_rating\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"MPAA_rating\"], prefix=[\"rating_is\"])\n",
    "df = pd.get_dummies(df, columns=[\"genre\"], prefix=[\"genre_is\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Encoding the release date to a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def date_to_float(dt):\n",
    "    # Calculating the months and days\n",
    "    calc = (((dt.month - 1) * 30) + dt.day) / 365\n",
    "    # Adding calc to the years\n",
    "    return dt.year + calc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Splitting date to days and months and then converting it to a scalar via `date_to_float()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['month'] = df['release_date'].dt.month\n",
    "df['day'] = df['release_date'].dt.day\n",
    "df['season'] = df['release_date'].dt.quarter\n",
    "df['release_date'] = df['release_date'].apply(date_to_float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Adding the budget and runtime columns from TMDb API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/2/train/preprocessed.csv')\n",
    "\n",
    "df['budget'] = np.nan\n",
    "df['runtime'] = np.nan\n",
    "\n",
    "movie = Movie()\n",
    "\n",
    "# extract the budget and runtime from the TMDb API\n",
    "for i, mov in df.iterrows():\n",
    "    search = movie.search(mov['name'])  # Search by the movie title\n",
    "    for res in search:\n",
    "        try:\n",
    "            # Confirming the search results by the release date year\n",
    "            print(movie.details(res.id).)\n",
    "            mov_date_str = str(mov['release_date'])\n",
    "            if int(res['release_date'][:4]) == int(mov_date_str[:4]):\n",
    "                # Editing the value at the original dataframe\n",
    "                detail = movie.details(res.id)\n",
    "                print(detail)\n",
    "                df.at[i, 'budget'] = detail['budget']\n",
    "                df.at[i, 'runtime'] = detail['runtime']\n",
    "                break\n",
    "        except BaseException as error:\n",
    "            pass\n",
    "            # print('An exception occurred: {}'.format(error) + \" \" + mov['name'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['budget'] = df['budget'].replace(0, df['budget'].median())\n",
    "df['budget'] = df['budget'].fillna(value=df['budget'].median())\n",
    "\n",
    "df['runtime'] = df['runtime'].replace(0, df['runtime'].median())\n",
    "df['runtime'] = df['runtime'].fillna(value=df['runtime'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Adjusting for inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cpi # https://pypi.org/project/cpi/\n",
    "\n",
    "# Update the CPI data\n",
    "cpi.update()\n",
    "\n",
    "# Adjust the revenue to inflation using cpi\n",
    "df['revenue'] = df.apply(lambda x: cpi.inflate(x['revenue'],\n",
    "                                               int(x.release_date)), axis=1)\n",
    "df['budget'] = df.apply(lambda x: cpi.inflate(x['budget'],\n",
    "                                              int(x.release_date)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_animation = pd.read_csv('datasets/2/train/movie-voice-actors.csv')\n",
    "\n",
    "# Remove duplicates on name column\n",
    "df_animation = df_animation.drop_duplicates(subset=['name'], keep='first')\n",
    "\n",
    "# Add column is_animation\n",
    "df_animation['is_animation'] = 1\n",
    "\n",
    "# Drop other columns that are not needed\n",
    "df_animation = df_animation.drop(['voice_actor', 'character'], axis=1)\n",
    "\n",
    "df_animation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Merging the animation dataset with the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge the animation dataset with the main dataset\n",
    "df = pd.merge(df, df_animation, on='name', how='left')\n",
    "\n",
    "# Fill the nulls with 0\n",
    "df['is_animation'] = df['is_animation'].fillna(value=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Encoding the movie success level to a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encoding the movie success level to a scalar\n",
    "df = pd.read_csv('datasets/2/train/preprocessed.csv')\n",
    "df['MovieSuccessLevel'] = df['MovieSuccessLevel'].map({'S': 5,\n",
    "                                                       'A': 4,\n",
    "                                                       'B': 3,\n",
    "                                                       'C': 2,\n",
    "                                                       'D': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Saving the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('datasets/2/train/preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dividing Data\n",
    "Y = df['MovieSuccessLevel']\n",
    "X = df.drop(['name', 'MovieSuccessLevel'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Data Splits\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=20, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------------- #\n",
    "\n",
    "# Hyper Parameters\n",
    "\n",
    "C = 0.00001  # SVM regularization parameter\n",
    "m_degree = 7\n",
    "\n",
    "# ------------------------------------- #\n",
    "\n",
    "# Poly Model\n",
    "poly_model = svm.SVC(kernel='poly', degree=m_degree, C=C).fit(X_train, Y_train)\n",
    "p = poly_model.predict(X_test)\n",
    "print(\"Accuracy Poly:\", metrics.accuracy_score(Y_test, p), '\\n')\n",
    "\n",
    "# ------------------------------------- #\n",
    "\n",
    "# Linear Model\n",
    "linear_svc = svm.LinearSVC(C=C).fit(X_train, Y_train)\n",
    "p = linear_svc.predict(X_test)\n",
    "print(\"Accuracy linear:\", metrics.accuracy_score(Y_test, p), '\\n')\n",
    "\n",
    "# ------------------------------------- #\n",
    "\n",
    "# Rbf Model\n",
    "rbf_svc = svm.SVC(kernel='rbf', C=C).fit(X_train, Y_train)\n",
    "p = rbf_svc.predict(X_test)\n",
    "print(\"Accuracy rbf:\", metrics.accuracy_score(Y_test, p), '\\n')\n",
    "\n",
    "# ------------------------------------- #\n",
    "\n",
    "# Linear Kernel Model\n",
    "linear_kernel_svc = svm.SVC(kernel='linear', C=C).fit(X_train, Y_train)\n",
    "p = linear_kernel_svc.predict(X_test)\n",
    "print(\"Accuracy Linear kernel:\", metrics.accuracy_score(Y_test, p), '\\n')\n",
    "\n",
    "# ------------------------------------- #\n",
    "\n",
    "# Logistic Regression Model\n",
    "logistic_regression_model = LogisticRegression(random_state=0).fit(X_train, Y_train)\n",
    "p = logistic_regression_model.predict(X_test)\n",
    "print(\"Accuracy Logistic Regression:\", metrics.accuracy_score(Y_test, p), '\\n')\n",
    "\n",
    "# ------------------------------------- #\n",
    "\n",
    "# Decision Tree Model\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "p = clf.predict(X_test)\n",
    "print(\"Accuracy Decision Tree:\", metrics.accuracy_score(Y_test, p), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
